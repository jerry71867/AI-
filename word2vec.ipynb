{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtBxXSg8PeWZ/B8aWXc8rr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerry71867/AI-/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlF159vD0qrB",
        "outputId": "17912182-4dd8-437c-b6d0-93a4ebf2d848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-23 09:42:06--  https://dumps.wikimedia.org/zhwiki/20240501/zhwiki-20240501-pages-articles-multistream1.xml-p1p187712.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.71, 2620:0:861:3:208:80:154:71\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 233419414 (223M) [application/octet-stream]\n",
            "Saving to: ‘zhwiki-20240501-pages-articles-multistream1.xml-p1p187712.bz2’\n",
            "\n",
            "zhwiki-20240501-pag 100%[===================>] 222.61M  4.33MB/s    in 48s     \n",
            "\n",
            "2024-05-23 09:42:55 (4.63 MB/s) - ‘zhwiki-20240501-pages-articles-multistream1.xml-p1p187712.bz2’ saved [233419414/233419414]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget https://dumps.wikimedia.org/zhwiki/20240501/zhwiki-20240501-pages-articles-multistream1.xml-p1p187712.bz2\n",
        "#使用wget工具從指定的URL下載中文維基百科的一部分數據。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencc-python-reimplemented\n",
        "#安裝opencc-python-reimplemented庫，用於進行中文簡繁體轉換。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3RFXC9w1Dg2",
        "outputId": "b7ea87b1-b819-48bb-b6d5-54cb76a64c76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencc-python-reimplemented\n",
            "  Downloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/481.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/481.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc-python-reimplemented\n",
            "Successfully installed opencc-python-reimplemented-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import WikiCorpus\n",
        "#從gensim.corpora模組中匯入WikiCorpus類別，用於處理維基百科 XML 轉儲文件\n",
        "wiki_corpus = WikiCorpus('zhwiki-20240501-pages-articles-multistream1.xml-p1p187712.bz2', dictionary={})\n",
        "#創建了一個WikiCorpus類別的實例，用來處理指定的維基百科XML轉儲文件。"
      ],
      "metadata": {
        "id": "ma7jQxyy1FbG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wiki_corpus\n",
        "#顯示wiki_corpus變數的內容。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSk475ki1Hue",
        "outputId": "27711c54-9863-4e18-abcc-7ed79b29ca97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.wikicorpus.WikiCorpus at 0x7e5d589198a0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(wiki_corpus.get_texts()))[:10]\n",
        "#從wiki_corpus中提取第一篇維基百科文章的文本，並顯示這篇文章的前10個單詞。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZPlwLzS1I9e",
        "outputId": "f6ea94c0-0198-48ec-aaea-65a0b84e5b93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['歐幾里得',\n",
              " '西元前三世紀的古希臘數學家',\n",
              " '而現在被認為是幾何之父',\n",
              " '此畫為拉斐爾的作品',\n",
              " '雅典學院',\n",
              " '数学',\n",
              " '是研究數量',\n",
              " '屬於形式科學的一種',\n",
              " '數學利用抽象化和邏輯推理',\n",
              " '從計數']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_num = 0\n",
        "#初始化一個計數器text_num，用於記錄處理的文章數量\n",
        "\n",
        "with open('wiki_text.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in wiki_corpus.get_texts():\n",
        "        f.write(' '.join(text)+'\\n')\n",
        "        text_num += 1\n",
        "        if text_num % 10000 == 0:\n",
        "            print('{} articles processed.'.format(text_num))\n",
        "\n",
        "    print('{} articles processed.'.format(text_num))\n",
        "\"\"\"\n",
        "從wiki_corpus中提取每篇文章的文本，\n",
        "將其寫入wiki_text.txt文件中，\n",
        "同時記錄並打印已處理的文章數量，每處理10000篇文章打印一次進度消息。\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "dwpI-vXx1Krv",
        "outputId": "d00b3099-9255-48ba-c305-7c15a3c381cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 articles processed.\n",
            "20000 articles processed.\n",
            "30000 articles processed.\n",
            "32786 articles processed.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n從wiki_corpus中提取每篇文章的文本，\\n將其寫入wiki_text.txt文件中，\\n同時記錄並打印已處理的文章數量，每處理10000篇文章打印一次進度消息。\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "#匯入jieba庫，用於中文將中文文本分割成單詞或短語。\n",
        "from opencc import OpenCC\n",
        "#從opencc模組中匯入OpenCC類別，用於中文簡繁轉換。"
      ],
      "metadata": {
        "id": "43Z_c7ay1M13"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc = OpenCC('s2t')\n",
        "#創建了一個OpenCC類的實例cc，並設置轉換配置為's2t'，將簡體中文轉換為繁體中文。\n",
        "train_data = open('wiki_text.txt', 'r', encoding='utf-8').read()\n",
        "#讀取整個文件內容，將其存儲在變數train_data中。\n",
        "train_data = cc.convert(train_data)\n",
        "#將文本從簡體中文轉換為繁體中文，並存儲回train_data。\n",
        "train_data = jieba.lcut(train_data)\n",
        "#將文本切分為單詞列表，並將結果存儲在train_data中。\n",
        "train_data = [word for word in train_data if word != '']\n",
        "#使用列表推導式過濾掉train_data中的空字符串，保留非空的單詞。\n",
        "train_data = ' '.join(train_data)\n",
        "#將train_data中的單詞列表連接成一個字符串，單詞之間用空格分隔。\n",
        "open('seg.txt', 'w', encoding='utf-8').write(train_data)\n",
        "#將train_data中的內容寫入seg.txt中。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XZ70id01OSP",
        "outputId": "42dd46fe-67b1-4ffa-a5ea-09f30afc0ca0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.848 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.848 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136623985"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "#從gensim.models模組中匯入word2vec類，用於訓練詞嵌入模型。\n",
        "\n",
        "# Settings\n",
        "seed = 666\n",
        "sg = 0\n",
        "window_size = 10\n",
        "#vector_size = 100\n",
        "min_count = 1\n",
        "workers = 8\n",
        "#epochs = 5\n",
        "batch_words = 10000\n",
        "\n",
        "train_data = word2vec.LineSentence('seg.txt')\n",
        "#讀取seg.txt文件中的訓練數據，並將其轉換為LineSentence對象。\n",
        "model = word2vec.Word2Vec(\n",
        "    train_data,\n",
        "    min_count=min_count,\n",
        "    #size=vector_size,\n",
        "    workers=workers,\n",
        "    #iter=epochs,\n",
        "    window=window_size,\n",
        "    sg=sg,\n",
        "    seed=seed,\n",
        "    #隨機數生成器的種子。\n",
        "    batch_words=batch_words\n",
        ")\n",
        "\n",
        "model.save('word2vec.model')\n",
        "#將訓練好的Word2Vec模型保存為word2vec.model文件。"
      ],
      "metadata": {
        "id": "w616i6Z31Qf-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "#從gensim.models模組中匯入word2vec類，用於訓練和使用詞嵌入模型。\n",
        "\n",
        "string = '電腦'\n",
        "#定義了一個字符串變數string。\n",
        "model = word2vec.Word2Vec.load('word2vec.model')\n",
        "#加載之前訓練並保存的Word2Vec模型。\n",
        "print(string)\n",
        "#打印變數string的值。\n",
        "\n",
        "for item in model.wv.most_similar(string):\n",
        "#用模型的most_similar方法來查找與string最相似的詞語。\n",
        "    print(item)\n",
        "    #打印每個相似詞及其相似度分數。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsLErBDM1Tnf",
        "outputId": "9d6cc0cb-82e1-40b3-a760-ff801e348a5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "電腦\n",
            "('計算機', 0.7763551473617554)\n",
            "('軟體', 0.7703704237937927)\n",
            "('硬體', 0.7457119822502136)\n",
            "('pc', 0.736448347568512)\n",
            "('pda', 0.735950767993927)\n",
            "('ibm', 0.7298195362091064)\n",
            "('程式', 0.7265124320983887)\n",
            "('手機', 0.7238978147506714)\n",
            "('模擬器', 0.7175567150115967)\n",
            "('遊戲機', 0.7164707183837891)\n"
          ]
        }
      ]
    }
  ]
}